{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba1244a-f70a-482f-9f7c-04e187a28d35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# <font color='red'>**KANDINSKY**</font>: Clustering and Quantization   \n",
    "  \n",
    "## **Prep the Photographs**  \n",
    "\n",
    "*Shaurya Agarwal*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c6f1b-7e6a-4162-b5b8-2d98a27e6a3a",
   "metadata": {},
   "source": [
    "![K-Means and Friends](./images/Data_Analysis_BG_1200.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a4b33-4f2e-4795-929a-bb0f574a5cd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### <font color='green'>__Support for Google Colab__  </font>  \n",
    "    \n",
    "open this notebook in Colab using the following button:  \n",
    "  \n",
    "<a href=\"https://colab.research.google.com/github/shauryashaurya/kandinsky/blob/master/01-K-Means-and-friends-prep-the-photos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>  \n",
    "  \n",
    "<font color='green'>uncomment and execute the cell below to setup and run this notebook on Google Colab.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4e11d5-4cc7-4bde-b032-9b4c5c8cd52f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # SETUP FOR COLAB: select all the lines below and uncomment (CTRL+/ on windows)\n",
    "# # Image conversion methods use OpenCV \n",
    "\n",
    "# ! pip install --upgrade --no-cache-dir jax cv2 numpy pandas skimage scikit-learn\n",
    "\n",
    "# ! mkdir ./data\n",
    "# ! mkdir ./data/cgi\n",
    "# ! mkdir ./data/edtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0e549-3e85-4202-80a8-3162ff445048",
   "metadata": {},
   "source": [
    "## Setup, imports etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f16011-7d45-4be1-ae93-efbfe2fb8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage import color\n",
    "# \n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012ce581-5a1d-4734-b73a-f6ab70b34284",
   "metadata": {},
   "source": [
    "To render Matplotlib plots directly in a JupyterLab notebook, you can use the ```%matplotlib inline``` magic command. This command configures Matplotlib to render its plots inline within the Jupyter notebook cells, immediately below the code cells that produce them.  \n",
    "For interactive plots within JupyterLab (e.g., for zooming and rotating 3D plots), you can use the ```%matplotlib widget``` magic instead.  \n",
    "```%matplotlib widget``` requires ```ipympl``` package, ```pip install --upgrade --no-cache-dir ipympl``` if it's missing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0fbd9e-51f0-46a7-9942-79db44201fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85904f2c-578d-49cd-9a37-1e6df5933f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to make plotly plots show up in the notebook\n",
    "# pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6470418-d9d4-4e74-a2bb-0f69c8030057",
   "metadata": {},
   "source": [
    "# A look at our Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861bfe9-fbcb-487f-b34f-fcee63533ac6",
   "metadata": {},
   "source": [
    "To easily display images in the notebook, use this code:\n",
    "```\n",
    "![Image Title](Image Path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71b822dd-52d8-4b58-a905-9bf49b817c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you *HAD* to do it this way, otherwise just use markdown...or HTML\n",
    "# from IPython.display import Image as IPImage\n",
    "\n",
    "# def display_image(image_path):\n",
    "#     \"\"\"Display an image using IPython display.\"\"\"\n",
    "#     display(IPImage(filename=image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c49931-c226-4f88-9604-91c6f0de8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blows up the size of the notebook\n",
    "# display_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637d3de-e582-4c27-85f2-594e03c62b3f",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ce641-410f-44f7-964b-475ab94b6ad2",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83411c05-7f80-4678-ae22-e78251c6e275",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/003.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b2e94-29ff-4ec0-a1c3-0160b677fee7",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/004.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc5a805-53c0-4edb-9cf0-201211b6c6f0",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/005.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b44d3-f667-46f2-a6bd-8d7334ae6659",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/006.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1c725-1004-4336-81e8-9f76608abf48",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/007.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836b6da-f904-4448-9fdc-bf75a4b78f7b",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/008.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c05f41-92b5-4466-8bd3-563e8949fe51",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/009.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11427d25-dd50-4834-bfe2-8058754c6b86",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/010.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b99978-d658-4ea1-b7f1-1ace6d99bd44",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/011.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015737b6-c58f-4b5a-ab0d-143a5702efd7",
   "metadata": {},
   "source": [
    "![sample image](./data/edtf/012.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac73f5-1a22-40f7-a096-dfec122f217f",
   "metadata": {},
   "source": [
    "## Pre-processing images to generate data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e771d8-143d-4559-94a6-92ae7ad26011",
   "metadata": {},
   "source": [
    "Let's try to load an image and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8d7a8c-bccf-4c57-a1a0-3ec29f068f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157500, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(\"./data/cgi/\" + \"01x25.png\")\n",
    "\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_rgb.shape\n",
    "img2 = image_rgb.reshape((-1, image_rgb.shape[2]))\n",
    "img2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235c8a2-3ee6-44b4-85a5-2fcc87d65de4",
   "metadata": {},
   "source": [
    "So about 157500 pixels, each with 3 values - red, green and blue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55069710-afde-4d50-abe0-97f56677b9dd",
   "metadata": {},
   "source": [
    "### References:  \n",
    "* Look at the color conversion codes here: https://docs.opencv.org/4.9.0/de/d25/imgproc_color_conversions.html  \n",
    "* OpenCV Image transformation Enumerations: https://docs.opencv.org/3.4.0/d7/d1b/group__imgproc__misc.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26bec4b-1e07-44cf-98c6-478fe14bf707",
   "metadata": {},
   "source": [
    "Save the RGB image as CSV data - we'll use these to perform clustering operations later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af351711-58be-4ea2-b304-5e260e7f4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert image to specified color space and save to CSV\n",
    "# the method image_to_color_spaces_parallel() uses this\n",
    "def convert_and_save(image_path, conversion_func, suffix, header):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image using the provided conversion function\n",
    "    converted_image = conversion_func(image_rgb)\n",
    "\n",
    "    # Flatten the image array to list pixels\n",
    "    pixels = converted_image.reshape((-1, converted_image.shape[2]))\n",
    "    # print('suffix: ', suffix, ' sample pixels: ', pixels[:3])\n",
    "\n",
    "    # Save to CSV\n",
    "    base_path = image_path.rsplit(\".\", 1)[0]\n",
    "    output_path = f\"{base_path}_{suffix}.csv\"\n",
    "\n",
    "    # Using NumPy to directly save to CSV\n",
    "    np.savetxt(\n",
    "        output_path,\n",
    "        pixels,\n",
    "        delimiter=\",\",\n",
    "        header=\",\".join(header),\n",
    "        comments=\"\",\n",
    "        encoding=\"utf-8\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e120d708-072d-48f6-8ceb-a35320b6faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert image to various color spaces using parallel processing. \n",
    "# Calls 1 in turn\n",
    "def image_to_color_spaces_parallel(image_path):\n",
    "    \n",
    "    # Define conversion functions\n",
    "    def to_rgb(image_rgb):\n",
    "        return image_rgb\n",
    "\n",
    "    def to_xyz(image_rgb):\n",
    "        return cv2.cvtColor(image_rgb, cv2.COLOR_RGB2XYZ)\n",
    "\n",
    "    def to_lab(image_rgb):\n",
    "        return cv2.cvtColor(image_rgb, cv2.COLOR_RGB2Lab)\n",
    "\n",
    "    def to_hsv(image_rgb):\n",
    "        return cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # TODO: HSL no supported in skimage.color, build support using other libraries later\n",
    "    def to_hsl(image_rgb):\n",
    "        return cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HLS)  # OpenCV uses HLS naming\n",
    "\n",
    "    # Conversion specifications (function, suffix, header)\n",
    "    conversions = [\n",
    "        (to_rgb, \"RGB\", [\"R\", \"G\", \"B\"]),\n",
    "        (to_xyz, \"XYZ\", [\"X\", \"Y\", \"Z\"]),\n",
    "        (to_lab, \"Lab\", [\"L*\", \"a*\", \"b*\"]),\n",
    "        (to_hsv, \"HSV\", [\"H\", \"S\", \"V\"]),\n",
    "        (to_hsl, \"HSL\", [\"H\", \"S\", \"L\"]),\n",
    "    ]\n",
    "    for func, suff, header in conversions:\n",
    "        convert_and_save(image_path, func, suff, header)\n",
    "\n",
    "    # # [TODO] Use ThreadPoolExecutor to parallelize conversions\n",
    "    # with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # \tfutures = [executor.submit(convert_and_save, image_path, func, suffix, header)\n",
    "    # \t\tfor func, suffix, header in conversions]\n",
    "\n",
    "    # # Wait for all futures to complete\n",
    "    # concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09badac0-46cd-495b-92c0-fcee657a7474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing image:  01x25.png\n",
      "pre-processing image:  02x25.png\n",
      "pre-processing image:  03x25.png\n",
      "pre-processing image:  04x25.png\n",
      "pre-processing image:  05x25.png\n",
      "pre-processing image:  06x25.png\n"
     ]
    }
   ],
   "source": [
    "# Save sample images in a variety of color models\n",
    "images = [\"01x25.png\", \"02x25.png\", \"03x25.png\", \"04x25.png\", \"05x25.png\", \"06x25.png\"]\n",
    "for image in images:\n",
    "    print(\"pre-processing image: \", image)\n",
    "    image_path = \"./data/cgi/\" + image\n",
    "    image_to_color_spaces_parallel(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0040518-49ef-42f9-a96c-7573a9bb4fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing image:  001.png\n",
      "pre-processing image:  002.png\n",
      "pre-processing image:  003.png\n",
      "pre-processing image:  004.png\n",
      "pre-processing image:  005.png\n",
      "pre-processing image:  006.png\n",
      "pre-processing image:  007.png\n",
      "pre-processing image:  008.png\n",
      "pre-processing image:  009.png\n",
      "pre-processing image:  010.png\n",
      "pre-processing image:  011.png\n",
      "pre-processing image:  012.png\n"
     ]
    }
   ],
   "source": [
    "# Do this for Eight-Down-Toofaan-Mail photographs as well\n",
    "images = ['001.png','002.png','003.png','004.png','005.png','006.png','007.png','008.png','009.png','010.png','011.png','012.png']\n",
    "for image in images:\n",
    "    print(\"pre-processing image: \", image)\n",
    "    image_path = \"./data/edtf/\" + image\n",
    "    image_to_color_spaces_parallel(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
